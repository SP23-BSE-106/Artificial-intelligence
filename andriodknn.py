# -*- coding: utf-8 -*-
"""AndriodKNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14NHoMs3fN1EkKMEnlPaFZqvca_hUIECn
"""

# Mount your Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Import pandas
import pandas as pd

# Load your dataset (make sure this path is correct)
df = pd.read_csv('/content/drive/MyDrive/AI_LAB/Android_Malware.csv')

# Show first few rows to confirm it's loaded
df.head()

# -----------------------------------------------
# üß† KNN Classifier on Android Malware Dataset
# -----------------------------------------------
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

# Load again with low_memory=False to avoid dtype warnings
df = pd.read_csv('/content/drive/MyDrive/AI_LAB/Android_Malware.csv', low_memory=False)

# Drop columns that are not useful for prediction
drop_cols = ['Unnamed: 0', 'Flow ID', 'Source IP', 'Destination IP', 'Timestamp']
df = df.drop(columns=drop_cols, errors='ignore')

# Encode the 'Label' column (string labels ‚Üí numeric)
label_encoder = LabelEncoder()
df['Label'] = label_encoder.fit_transform(df['Label'])

# Separate features (X) and target (y)
X = df.drop('Label', axis=1)
y = df['Label']

# Replace non-numeric or missing values
X = X.apply(pd.to_numeric, errors='coerce')
X = X.fillna(X.mean())

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=43
)

# Create and train KNN model
model = KNeighborsClassifier(n_neighbors=3)
model.fit(X_train, y_train)

# Predict
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

# Evaluate
train_acc = accuracy_score(y_train, y_train_pred)
test_acc = accuracy_score(y_test, y_test_pred)

print("Training Accuracy:", round(train_acc, 3))
print("Testing Accuracy:", round(test_acc, 3))

# Interpretation
if abs(train_acc - test_acc) < 0.1 and train_acc > 0.8:
    print("\n‚úÖ Model generalizes well.")
elif train_acc > test_acc + 0.2:
    print("\n‚ö†Ô∏è Model might be overfitting.")
else:
    print("\n‚ùå Model might be underfitting.")

drop_cols = ['Unnamed: 0', 'Flow ID', 'Source IP', 'Destination IP', 'Timestamp']
df = df.drop(columns=drop_cols, errors='ignore')
df.head()

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df['Label'] = le.fit_transform(df['Label'])
df['Label'].unique()

df = df.apply(pd.to_numeric, errors='coerce')
df.info()

df = df.fillna(df.mean())

X = df.drop('Label', axis=1)
y = df['Label']

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=43
)

from sklearn.neighbors import KNeighborsClassifier

model = KNeighborsClassifier(n_neighbors=7)
model.fit(X_train, y_train)

print("Training:", model.score(X_train, y_train))
print("Testing:", model.score(X_test, y_test))

for k in range(1, 21):
    model = KNeighborsClassifier(n_neighbors=k)
    model.fit(X_train, y_train)
    print(f"k={k}, Train={model.score(X_train, y_train):.3f}, Test={model.score(X_test, y_test):.3f}")