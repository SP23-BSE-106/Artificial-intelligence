# -*- coding: utf-8 -*-
"""ANDRIOD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jvjnRsEHqXTr38LHYnf23ta5mk8tQ1Eq
"""

import numpy
import pandas
import matplotlib

from google.colab import drive
drive.mount('/content/drive')
import pandas as pd
df = pd.read_csv('/content/drive/MyDrive/AI_LAB/Android_Malware.csv')

df.head()

print(df.head())

print(df.shape)

print(df.columns)

print(df.info())

print(df.describe())

print(df.size)

print(df.isnull().sum())

# === üìä DATA INSPECTION SECTION ===
print("===== Dataset Overview =====")
print("Shape (Rows, Columns):", df.shape)
print("Total Elements:", df.size)
print("\n===== Column Names =====")
print(list(df.columns))

print("\n===== Null Values per Column =====")
print(df.isnull().sum())

print("\nAny Null Values Present?:", df.isnull().values.any())

print("\n===== Duplicate Rows =====")
print("Total Duplicates:", df.duplicated().sum())

print("\n===== Duplicate Columns (if any) =====")
print(df.columns[df.columns.duplicated()])

print("\n===== Data Types of Each Column =====")
print(df.dtypes)

print("\n===== Statistical Summary (Numeric Columns) =====")
print(df.describe())

# ==========================
# üìä DATA VISUALIZATION CODE
# ==========================

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# === 0Ô∏è‚É£ LOAD DATASET ===
data = pd.read_csv('/content/drive/MyDrive/AI_LAB/Android_Malware.csv')

# === 1Ô∏è‚É£ BASIC INFO ===
print("‚úÖ Dataset Loaded Successfully!\n")
print("Shape of Dataset:", data.shape)
print("\nColumns:\n", data.columns)
print("\nNull Values:\n", data.isnull().sum())
print("\nDuplicate Rows:", data.duplicated().sum())

# === 2Ô∏è‚É£ PIE CHART (for 'label' or 'class' columns) ===
if 'label' in data.columns or 'class' in data.columns:
    col = 'label' if 'label' in data.columns else 'class'
    data[col].value_counts().plot(
        kind='pie',
        autopct='%1.1f%%',
        colors=plt.cm.Paired.colors,
        startangle=90,
        shadow=True
    )
    plt.title(f'Distribution of {col}')
    plt.ylabel('')
    plt.show()
else:
    print("‚ö†Ô∏è No 'label' or 'class' column found for pie chart.\n")

# === 3Ô∏è‚É£ HISTOGRAM for all numerical columns ===
data.hist(figsize=(12, 10), bins=20, color='skyblue', edgecolor='black')
plt.suptitle('Histogram of Numerical Features', fontsize=14)
plt.show()

# === 4Ô∏è‚É£ CORRELATION HEATMAP (only for numeric columns) ===
plt.figure(figsize=(10, 8))
numeric_data = data.select_dtypes(include=['int64', 'float64'])

if not numeric_data.empty:
    sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm')
    plt.title('Feature Correlation Heatmap (Numeric Only)')
    plt.show()
else:
    print("‚ö†Ô∏è No numeric columns found for correlation heatmap.\n")

# === 5Ô∏è‚É£ BAR CHART (Top 10 Categories for each object column) ===
for col in data.select_dtypes(include=['object']).columns:
    plt.figure(figsize=(8, 4))
    data[col].value_counts().head(10).plot(kind='bar', color='teal')
    plt.title(f'Top 10 Categories in {col}')
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.show()

print("\nüéâ Visualization Completed Successfully!")

"""### üß† MACHINE LEARNING (ML) MODELS

1. **Linear Regression** ‚Äì Predicts continuous numerical values.
2. **Logistic Regression** ‚Äì Used for binary classification (yes/no).
3. **Decision Tree** ‚Äì Splits data into branches based on feature values.
4. **Random Forest** ‚Äì An ensemble of decision trees for better accuracy.
5. **Support Vector Machine (SVM)** ‚Äì Finds the best boundary between classes.
6. **K-Nearest Neighbors (KNN)** ‚Äì Classifies based on similarity to nearby points.
7. **Naive Bayes** ‚Äì A probabilistic classifier, great for text classification.
8. **Gradient Boosting** ‚Äì Sequentially builds models to reduce errors.
9. **XGBoost** ‚Äì Optimized and fast gradient boosting algorithm.
10. **AdaBoost** ‚Äì Combines weak learners to form a strong classifier.

---

### ‚öôÔ∏è DEEP LEARNING (DL) MODELS

11. **Artificial Neural Network (ANN)** ‚Äì Basic building block of deep learning.
12. **Convolutional Neural Network (CNN)** ‚Äì Best for image recognition and analysis.
13. **Recurrent Neural Network (RNN)** ‚Äì Designed for sequential data (like text or time series).
14. **Long Short-Term Memory (LSTM)** ‚Äì A type of RNN that remembers long-term dependencies.
15. **Gated Recurrent Unit (GRU)** ‚Äì A simpler version of LSTM with similar performance.
16. **Autoencoder** ‚Äì Learns compressed representations of data.
17. **Generative Adversarial Network (GAN)** ‚Äì Generates new, synthetic data (like fake images).
18. **Transformer** ‚Äì Uses attention mechanism, foundation for GPT and BERT models.

---

### üëÅÔ∏è COMPUTER VISION (CV) MODELS

19. **LeNet-5** ‚Äì Early CNN used for handwritten digit recognition (MNIST).
20. **AlexNet** ‚Äì Revolutionized deep learning with ImageNet competition (2012).
21. **VGG16 / VGG19** ‚Äì Very deep CNN with simple and uniform architecture.
22. **ResNet** ‚Äì Introduced residual connections to train deeper networks.
23. **InceptionNet (GoogLeNet)** ‚Äì Extracts multi-scale image features.
24. **MobileNet** ‚Äì Lightweight CNN for mobile and embedded devices.
25. **YOLO (You Only Look Once)** ‚Äì Real-time object detection model.

---

### üó£Ô∏è NATURAL LANGUAGE PROCESSING (NLP) MODELS (BONUS)

* **BERT** ‚Äì Bidirectional transformer from Google for language understanding.
* **GPT (1‚Äì5)** ‚Äì Generative Pretrained Transformer by OpenAI (used for text generation).
* **RoBERTa** ‚Äì Robustly optimized version of BERT.
* **T5** ‚Äì Text-to-Text Transfer Transformer (converts any NLP task to text generation).
* **DistilBERT** ‚Äì A smaller, faster version of BERT.

---



"""